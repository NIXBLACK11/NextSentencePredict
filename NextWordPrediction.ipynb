{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE-euMqU8vjO",
        "outputId": "bebfacdd-1be7-4208-9178-7056a382f666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-29 06:54:00--  https://storage.googleapis.com/kaggle-data-sets/76821/172291/compressed/game_of_thrones.txt.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230828%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230828T102610Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=40cae359747b1558c72a76484a91a4c2bad0dceb582157b2e2d43c186524f90c05884944c00976787e8409abb64aba1fb6bae4def152ffec9c52c297a9ea1e6d0e501a65582a524e1e3adcc6e62a2e8b83a458aec3426aaf8518e4c5fec4a2b5d77a753ae9ef1c53ae4f0429a5eb1e65fa058379f7fbf42d52f1dcef10f38cf51107440d3d7a0ecd03841b04df8e4b04229d194f72398f0a38c87e231494ad80a4cc0b37f27d9c4fd7840deae0a5c0c7da430bb076da1e2fee4b0b1cff463c11b03470a283b89f9a0a8cf62f9e779c023b1462e4fced81a8ec764a17ec961dcf85651d3ea203ab4d8010d6ec1196961c7f0e281a98b5e5699b0402420725e77e\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.68.128, 64.233.170.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 614700 (600K) [application/zip]\n",
            "Saving to: ‘words.zip’\n",
            "\n",
            "words.zip           100%[===================>] 600.29K   727KB/s    in 0.8s    \n",
            "\n",
            "2023-08-29 06:54:02 (727 KB/s) - ‘words.zip’ saved [614700/614700]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://storage.googleapis.com/kaggle-data-sets/76821/172291/compressed/game_of_thrones.txt.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230828%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230828T102610Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=40cae359747b1558c72a76484a91a4c2bad0dceb582157b2e2d43c186524f90c05884944c00976787e8409abb64aba1fb6bae4def152ffec9c52c297a9ea1e6d0e501a65582a524e1e3adcc6e62a2e8b83a458aec3426aaf8518e4c5fec4a2b5d77a753ae9ef1c53ae4f0429a5eb1e65fa058379f7fbf42d52f1dcef10f38cf51107440d3d7a0ecd03841b04df8e4b04229d194f72398f0a38c87e231494ad80a4cc0b37f27d9c4fd7840deae0a5c0c7da430bb076da1e2fee4b0b1cff463c11b03470a283b89f9a0a8cf62f9e779c023b1462e4fced81a8ec764a17ec961dcf85651d3ea203ab4d8010d6ec1196961c7f0e281a98b5e5699b0402420725e77e\" -O words.zip\n",
        "!unzip words.zip > /dev/null\n",
        "!rm words.zip\n",
        "!mv game_of_thrones.txt text.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'text.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "content = content[:10000]\n",
        "\n",
        "print(len(content))\n",
        "# print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdphVWvA-fK_",
        "outputId": "0283b157-7ce3-492b-b630-9c6e62ba73f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "ignore_words = ['?', '.', '!', '$', '%', '&', ',', \"”\", \"“\"]\n",
        "\n",
        "def tokenize(sent):\n",
        "  return nltk.word_tokenize(sent)\n",
        "\n",
        "def processWords(words):\n",
        "  all_words = tokenize(words)\n",
        "  all_words = [word for word in all_words if word not in ignore_words]\n",
        "  all_words = sorted(set(all_words))\n",
        "  return all_words\n",
        "\n",
        "all_words = processWords(content)\n",
        "print(all_words)\n",
        "\n",
        "index_to_word = {i: word for i, word in enumerate(all_words)}\n",
        "word_to_index = {word: i for i, word in enumerate(all_words)}\n",
        "\n",
        "print(\"Index to Word:\")\n",
        "print(index_to_word)\n",
        "\n",
        "print(\"\\nWord to Index:\")\n",
        "print(word_to_index)\n"
      ],
      "metadata": {
        "id": "uY--UwXdAe2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a6e3be-defc-499b-9aad-d45bf42e7e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'\", \"'ll\", \"'re\", \"'s\", \"'ve\", ';', 'A', 'Aemon', 'All', 'And', 'Are', 'At', 'Best', 'Bet', 'Bright', 'Brother', 'But', 'Ca', 'Dead', 'Despite', 'Did', 'Do', 'Each', 'Eight', 'Especially', 'Ever', 'Everyone', 'Fallen', 'Fear', 'Fire', 'First', 'Frostfallen', 'Game', 'Gared', 'Have', 'He', 'Heavy-looking', 'His', 'I', 'Ice', 'If', 'Is', 'It', 'Leave', 'Liste', 'Maester', 'Mallister', 'Mallisters', 'Men', 'Mormont', 'Most', 'Mounted', 'My', 'Never', 'Night', 'Nine', 'No', 'Not', 'Nothing', 'One', 'Or', 'PROLOGUE', 'Peaceful', 'Perhaps', 'Royce', 'Ser', 'Some', 'Something', 'Somewhere', 'Song', 'Such', 'Sworn', 'Tell', 'The', 'Then', 'There', 'They', 'Thrones', 'Today', 'Twilight', 'Two', 'Under', 'Until', 'Wall', 'Watch', 'Waymar', 'We', 'Weeping', 'Well', 'What', 'When', 'Why', 'Will', 'Yes', 'Yet', 'You', 'a', 'about', 'above', 'accustomed', 'adjusted', 'admitted', 'after', 'afterward', 'again', 'against', 'all', 'an', 'ancient', 'and', 'anger', 'any', 'anything', 'are', 'around', 'as', 'asked', 'at', 'atop', 'away', 'axe', 'back', 'bait', 'band', 'barely', 'barracks', 'be', 'been', 'before', 'began', 'behind', 'being', 'believe', 'beneath', 'beside', 'best', 'better', 'beyond', 'black', 'blood', 'bloody', 'blowing', 'bodies', 'boiled', 'boots', 'both', 'bound', 'bowels', 'bows', 'boy', 'branches', 'brother', 'brothers', 'brought', 'bruise', 'bucks', 'burning', 'burns', 'business', 'but', 'by', 'called', 'came', 'camp', 'can', 'care', 'carefully', 'careless', 'casually', 'caught', 'certainty', 'chatter', 'children', 'chill', 'choice', 'clad', 'clear', 'cloak', 'close', 'closer', 'cloudless', 'coat', 'cocksure', 'cold', 'color', 'come', 'comes', 'commander', 'concerned', 'could', 'couple', 'covered', 'crowning', 'cruel', 'crust', 'cups', 'cut', 'dared', 'dark', 'darkness', 'day', 'days', 'dead', 'deep', 'deepened', 'deepening', 'deign', 'destrier', 'details', 'did', 'different', 'discover', 'disdainful', 'disinterest', 'dismounted', 'distance', 'do', 'does', 'done', 'double-bladed', 'down', 'dozen', 'drag', 'drape', 'draw', 'drawn', 'dream', 'dress', 'driving', 'drowsy', 'ear', 'ears', 'easier', 'echoed', 'edge', 'eight', 'eighteen', 'eloquence', 'else', 'end', 'endless', 'enemy', 'enough', 'even', 'ever', 'every', 'everything', 'eyes', 'face', 'fade', 'faded', 'fallen', 'falling', 'far-eyes', 'farther', 'fear', 'feel', 'feeling', 'feet', 'felt', 'few', 'fierce', 'fifty', 'fight', 'fill', 'find', 'fine', 'finger', 'fire', 'firepit', 'fires', 'first', 'flurry', 'flushed', 'foot', 'for', 'forest', 'fortnight', 'forty', 'found', 'four', 'freeriders', 'freeze', 'frighten', 'from', 'front', 'frosts', 'frowning', 'froze', 'frozen', 'full', 'fur', 'garron', 'garrons', 'gave', 'gets', 'getting', 'given', 'giving', 'glanced', 'glared', 'gleaming', 'glory', 'gloves', 'gnarled', 'go', 'good', 'got', 'graceful', 'grateful', 'great', 'grey-eyed', 'grizzled', 'ground', 'grow', 'grown', 'hackles', 'had', 'half', 'half-alive', 'half-bored', 'half-distracted', 'half-hid', 'half-moon', 'hand', 'handsome', 'hard', 'haunted', 'have', 'he', 'heads', 'hear', 'heirs', 'hellbent', 'here', 'hidden', 'him', 'himself', 'hint', 'his', 'holes', 'honor', 'hood', 'hope', 'horse', 'hot', 'house', 'how', 'howled', 'howling', 'huge', 'hunched', 'hundred', 'hunter', 'ice', 'if', 'impatiently', 'implacable', 'in', 'inside', 'insisted', 'insofar', 'insolent', 'interrupt', 'into', 'iron', 'ironwood', 'is', 'it', 'its', 'joined', 'just', 'kill', 'killed', 'knife', 'knight', 'known', 'lad', 'last', 'later', 'laugh', 'laughed', 'lay', 'layers', 'lead', 'lean-to', 'learned', 'least', 'leather', 'leaves', 'left', 'less', 'let', 'light', 'like', 'little', 'living', 'long', 'look', 'looked', 'lord', 'lordling', 'lordlings', 'losing', 'loud', 'loved', 'lying', \"m'lord\", 'made', 'make', 'making', 'man', 'man-at-arms', 'many', 'maybe', 'me', 'means', 'men', 'might', 'mighty', 'miles', 'milk', 'moleskin', 'moment', 'moon', 'more', 'mother', 'mount', 'mouth', 'move', 'moved', 'moving', 'much', 'mulled', 'must', 'muttered', 'my', 'myself', \"n't\", 'near', 'neither', 'nervous', 'never', 'next', 'nice', 'night', 'nine', 'no', 'nodded', 'north', 'northwest', 'not', 'note', 'nothing', 'now', 'nurse', 'obey', 'observed', 'of', 'off', 'old', 'older', 'on', 'one', 'only', 'or', 'order', 'orders', 'ought', 'our', 'out', 'over', 'own', 'pace', 'pain', 'pants', 'past', 'paused', 'perilous', 'picking', 'piece', 'plain', 'poacher', 'pointed', 'position', 'prepared', 'pretty', 'pride', 'proof', 'pulled', 'purple', 'put', 'putting', 'quarrel', 'quick', 'quieter', 'raiders', 'ranging', 'rangings', 'rather', 'real', 'rear', 'red', 'red-handed', 'reflected', 'reflective', 'remind', 'replied', 'reply', 'rest', 'restlessly', 'ridden', 'ride', 'ridge', 'riding', 'right', 'ringmail', 'rise', 'risen', 'rock', 'rode', 'roots', 'rose', 'rushing', 'rustle', 'sable', 'safety', 'said', 'same', 'sat', 'saw', 'say', 'says', 'scars', 'sea', 'see', 'seemed', 'seen', 'sense', 'sent', 'sha', 'shaggy', 'share', 'shared', 'she', 'shelter', 'shiver', 'shivered', 'shivering', 'should', 'shrugged', 'silent', 'sin', 'sing', 'sinking', 'sinks', 'sit', 'sitting', 'skinning', 'sky', 'sleep', 'sleeping', 'slender', 'smaller', 'smile', 'smiled', 'snorting', 'snow', 'snows', 'so', 'soft', 'softly', 'something', 'son', 'songs', 'sooner', 'southron', 'spent', 'stamp', 'staring', 'stars', 'start', 'starts', 'steals', 'still', 'stirred', 'stones', 'stopping', 'stories', 'storm', 'stream', 'strength', 'studied', 'stumps', 'suggested', 'sullen', 'supple', 'suppressed', 'surely', 'suspected', 'swords', 'take', 'taken', 'talent', 'talks', 'taste', 'teeth', 'tell', 'tension', 'terrors', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'thick', 'thing', 'things', 'think', 'thinly', 'this', 'though', 'three', 'through', 'tightness', 'time', 'tit', 'to', 'toes', 'told', 'tonight', 'too', 'took', 'toward', 'towered', 'track', 'trees', 'trouble', 'truth', 'try', 'turned', 'twilight', 'twilit', 'twisted', 'two', 'under', 'undergrowth', 'understand', 'unease', 'unmanned', 'unwary', 'up', 'urged', 'us', 'veteran', 'vocation', 'voice', 'waiting', 'wanted', 'wardrobe', 'warhorse', 'warm', 'warmly', 'warrior', 'was', 'watch', 'watched', 'watches', 'watching', 'water', 'way', 'we', 'weak', 'weapons', 'weather', 'week', 'weeping', 'well', 'went', 'were', 'wet', 'what', 'when', 'where', 'while', 'whispered', 'wilderness', 'wildling', 'wildlings', 'wind', 'wine', 'winter', 'wished', 'with', 'wolf', 'woman', 'women', 'wood', 'woods', 'wool', 'woolen', 'wore', 'worse', 'worst', 'would', 'wounded', 'wrong', 'year', 'years', 'you', 'young', 'youngest', 'your', 'youth']\n",
            "Index to Word:\n",
            "{0: \"'\", 1: \"'ll\", 2: \"'re\", 3: \"'s\", 4: \"'ve\", 5: ';', 6: 'A', 7: 'Aemon', 8: 'All', 9: 'And', 10: 'Are', 11: 'At', 12: 'Best', 13: 'Bet', 14: 'Bright', 15: 'Brother', 16: 'But', 17: 'Ca', 18: 'Dead', 19: 'Despite', 20: 'Did', 21: 'Do', 22: 'Each', 23: 'Eight', 24: 'Especially', 25: 'Ever', 26: 'Everyone', 27: 'Fallen', 28: 'Fear', 29: 'Fire', 30: 'First', 31: 'Frostfallen', 32: 'Game', 33: 'Gared', 34: 'Have', 35: 'He', 36: 'Heavy-looking', 37: 'His', 38: 'I', 39: 'Ice', 40: 'If', 41: 'Is', 42: 'It', 43: 'Leave', 44: 'Liste', 45: 'Maester', 46: 'Mallister', 47: 'Mallisters', 48: 'Men', 49: 'Mormont', 50: 'Most', 51: 'Mounted', 52: 'My', 53: 'Never', 54: 'Night', 55: 'Nine', 56: 'No', 57: 'Not', 58: 'Nothing', 59: 'One', 60: 'Or', 61: 'PROLOGUE', 62: 'Peaceful', 63: 'Perhaps', 64: 'Royce', 65: 'Ser', 66: 'Some', 67: 'Something', 68: 'Somewhere', 69: 'Song', 70: 'Such', 71: 'Sworn', 72: 'Tell', 73: 'The', 74: 'Then', 75: 'There', 76: 'They', 77: 'Thrones', 78: 'Today', 79: 'Twilight', 80: 'Two', 81: 'Under', 82: 'Until', 83: 'Wall', 84: 'Watch', 85: 'Waymar', 86: 'We', 87: 'Weeping', 88: 'Well', 89: 'What', 90: 'When', 91: 'Why', 92: 'Will', 93: 'Yes', 94: 'Yet', 95: 'You', 96: 'a', 97: 'about', 98: 'above', 99: 'accustomed', 100: 'adjusted', 101: 'admitted', 102: 'after', 103: 'afterward', 104: 'again', 105: 'against', 106: 'all', 107: 'an', 108: 'ancient', 109: 'and', 110: 'anger', 111: 'any', 112: 'anything', 113: 'are', 114: 'around', 115: 'as', 116: 'asked', 117: 'at', 118: 'atop', 119: 'away', 120: 'axe', 121: 'back', 122: 'bait', 123: 'band', 124: 'barely', 125: 'barracks', 126: 'be', 127: 'been', 128: 'before', 129: 'began', 130: 'behind', 131: 'being', 132: 'believe', 133: 'beneath', 134: 'beside', 135: 'best', 136: 'better', 137: 'beyond', 138: 'black', 139: 'blood', 140: 'bloody', 141: 'blowing', 142: 'bodies', 143: 'boiled', 144: 'boots', 145: 'both', 146: 'bound', 147: 'bowels', 148: 'bows', 149: 'boy', 150: 'branches', 151: 'brother', 152: 'brothers', 153: 'brought', 154: 'bruise', 155: 'bucks', 156: 'burning', 157: 'burns', 158: 'business', 159: 'but', 160: 'by', 161: 'called', 162: 'came', 163: 'camp', 164: 'can', 165: 'care', 166: 'carefully', 167: 'careless', 168: 'casually', 169: 'caught', 170: 'certainty', 171: 'chatter', 172: 'children', 173: 'chill', 174: 'choice', 175: 'clad', 176: 'clear', 177: 'cloak', 178: 'close', 179: 'closer', 180: 'cloudless', 181: 'coat', 182: 'cocksure', 183: 'cold', 184: 'color', 185: 'come', 186: 'comes', 187: 'commander', 188: 'concerned', 189: 'could', 190: 'couple', 191: 'covered', 192: 'crowning', 193: 'cruel', 194: 'crust', 195: 'cups', 196: 'cut', 197: 'dared', 198: 'dark', 199: 'darkness', 200: 'day', 201: 'days', 202: 'dead', 203: 'deep', 204: 'deepened', 205: 'deepening', 206: 'deign', 207: 'destrier', 208: 'details', 209: 'did', 210: 'different', 211: 'discover', 212: 'disdainful', 213: 'disinterest', 214: 'dismounted', 215: 'distance', 216: 'do', 217: 'does', 218: 'done', 219: 'double-bladed', 220: 'down', 221: 'dozen', 222: 'drag', 223: 'drape', 224: 'draw', 225: 'drawn', 226: 'dream', 227: 'dress', 228: 'driving', 229: 'drowsy', 230: 'ear', 231: 'ears', 232: 'easier', 233: 'echoed', 234: 'edge', 235: 'eight', 236: 'eighteen', 237: 'eloquence', 238: 'else', 239: 'end', 240: 'endless', 241: 'enemy', 242: 'enough', 243: 'even', 244: 'ever', 245: 'every', 246: 'everything', 247: 'eyes', 248: 'face', 249: 'fade', 250: 'faded', 251: 'fallen', 252: 'falling', 253: 'far-eyes', 254: 'farther', 255: 'fear', 256: 'feel', 257: 'feeling', 258: 'feet', 259: 'felt', 260: 'few', 261: 'fierce', 262: 'fifty', 263: 'fight', 264: 'fill', 265: 'find', 266: 'fine', 267: 'finger', 268: 'fire', 269: 'firepit', 270: 'fires', 271: 'first', 272: 'flurry', 273: 'flushed', 274: 'foot', 275: 'for', 276: 'forest', 277: 'fortnight', 278: 'forty', 279: 'found', 280: 'four', 281: 'freeriders', 282: 'freeze', 283: 'frighten', 284: 'from', 285: 'front', 286: 'frosts', 287: 'frowning', 288: 'froze', 289: 'frozen', 290: 'full', 291: 'fur', 292: 'garron', 293: 'garrons', 294: 'gave', 295: 'gets', 296: 'getting', 297: 'given', 298: 'giving', 299: 'glanced', 300: 'glared', 301: 'gleaming', 302: 'glory', 303: 'gloves', 304: 'gnarled', 305: 'go', 306: 'good', 307: 'got', 308: 'graceful', 309: 'grateful', 310: 'great', 311: 'grey-eyed', 312: 'grizzled', 313: 'ground', 314: 'grow', 315: 'grown', 316: 'hackles', 317: 'had', 318: 'half', 319: 'half-alive', 320: 'half-bored', 321: 'half-distracted', 322: 'half-hid', 323: 'half-moon', 324: 'hand', 325: 'handsome', 326: 'hard', 327: 'haunted', 328: 'have', 329: 'he', 330: 'heads', 331: 'hear', 332: 'heirs', 333: 'hellbent', 334: 'here', 335: 'hidden', 336: 'him', 337: 'himself', 338: 'hint', 339: 'his', 340: 'holes', 341: 'honor', 342: 'hood', 343: 'hope', 344: 'horse', 345: 'hot', 346: 'house', 347: 'how', 348: 'howled', 349: 'howling', 350: 'huge', 351: 'hunched', 352: 'hundred', 353: 'hunter', 354: 'ice', 355: 'if', 356: 'impatiently', 357: 'implacable', 358: 'in', 359: 'inside', 360: 'insisted', 361: 'insofar', 362: 'insolent', 363: 'interrupt', 364: 'into', 365: 'iron', 366: 'ironwood', 367: 'is', 368: 'it', 369: 'its', 370: 'joined', 371: 'just', 372: 'kill', 373: 'killed', 374: 'knife', 375: 'knight', 376: 'known', 377: 'lad', 378: 'last', 379: 'later', 380: 'laugh', 381: 'laughed', 382: 'lay', 383: 'layers', 384: 'lead', 385: 'lean-to', 386: 'learned', 387: 'least', 388: 'leather', 389: 'leaves', 390: 'left', 391: 'less', 392: 'let', 393: 'light', 394: 'like', 395: 'little', 396: 'living', 397: 'long', 398: 'look', 399: 'looked', 400: 'lord', 401: 'lordling', 402: 'lordlings', 403: 'losing', 404: 'loud', 405: 'loved', 406: 'lying', 407: \"m'lord\", 408: 'made', 409: 'make', 410: 'making', 411: 'man', 412: 'man-at-arms', 413: 'many', 414: 'maybe', 415: 'me', 416: 'means', 417: 'men', 418: 'might', 419: 'mighty', 420: 'miles', 421: 'milk', 422: 'moleskin', 423: 'moment', 424: 'moon', 425: 'more', 426: 'mother', 427: 'mount', 428: 'mouth', 429: 'move', 430: 'moved', 431: 'moving', 432: 'much', 433: 'mulled', 434: 'must', 435: 'muttered', 436: 'my', 437: 'myself', 438: \"n't\", 439: 'near', 440: 'neither', 441: 'nervous', 442: 'never', 443: 'next', 444: 'nice', 445: 'night', 446: 'nine', 447: 'no', 448: 'nodded', 449: 'north', 450: 'northwest', 451: 'not', 452: 'note', 453: 'nothing', 454: 'now', 455: 'nurse', 456: 'obey', 457: 'observed', 458: 'of', 459: 'off', 460: 'old', 461: 'older', 462: 'on', 463: 'one', 464: 'only', 465: 'or', 466: 'order', 467: 'orders', 468: 'ought', 469: 'our', 470: 'out', 471: 'over', 472: 'own', 473: 'pace', 474: 'pain', 475: 'pants', 476: 'past', 477: 'paused', 478: 'perilous', 479: 'picking', 480: 'piece', 481: 'plain', 482: 'poacher', 483: 'pointed', 484: 'position', 485: 'prepared', 486: 'pretty', 487: 'pride', 488: 'proof', 489: 'pulled', 490: 'purple', 491: 'put', 492: 'putting', 493: 'quarrel', 494: 'quick', 495: 'quieter', 496: 'raiders', 497: 'ranging', 498: 'rangings', 499: 'rather', 500: 'real', 501: 'rear', 502: 'red', 503: 'red-handed', 504: 'reflected', 505: 'reflective', 506: 'remind', 507: 'replied', 508: 'reply', 509: 'rest', 510: 'restlessly', 511: 'ridden', 512: 'ride', 513: 'ridge', 514: 'riding', 515: 'right', 516: 'ringmail', 517: 'rise', 518: 'risen', 519: 'rock', 520: 'rode', 521: 'roots', 522: 'rose', 523: 'rushing', 524: 'rustle', 525: 'sable', 526: 'safety', 527: 'said', 528: 'same', 529: 'sat', 530: 'saw', 531: 'say', 532: 'says', 533: 'scars', 534: 'sea', 535: 'see', 536: 'seemed', 537: 'seen', 538: 'sense', 539: 'sent', 540: 'sha', 541: 'shaggy', 542: 'share', 543: 'shared', 544: 'she', 545: 'shelter', 546: 'shiver', 547: 'shivered', 548: 'shivering', 549: 'should', 550: 'shrugged', 551: 'silent', 552: 'sin', 553: 'sing', 554: 'sinking', 555: 'sinks', 556: 'sit', 557: 'sitting', 558: 'skinning', 559: 'sky', 560: 'sleep', 561: 'sleeping', 562: 'slender', 563: 'smaller', 564: 'smile', 565: 'smiled', 566: 'snorting', 567: 'snow', 568: 'snows', 569: 'so', 570: 'soft', 571: 'softly', 572: 'something', 573: 'son', 574: 'songs', 575: 'sooner', 576: 'southron', 577: 'spent', 578: 'stamp', 579: 'staring', 580: 'stars', 581: 'start', 582: 'starts', 583: 'steals', 584: 'still', 585: 'stirred', 586: 'stones', 587: 'stopping', 588: 'stories', 589: 'storm', 590: 'stream', 591: 'strength', 592: 'studied', 593: 'stumps', 594: 'suggested', 595: 'sullen', 596: 'supple', 597: 'suppressed', 598: 'surely', 599: 'suspected', 600: 'swords', 601: 'take', 602: 'taken', 603: 'talent', 604: 'talks', 605: 'taste', 606: 'teeth', 607: 'tell', 608: 'tension', 609: 'terrors', 610: 'than', 611: 'that', 612: 'the', 613: 'their', 614: 'them', 615: 'then', 616: 'there', 617: 'these', 618: 'they', 619: 'thick', 620: 'thing', 621: 'things', 622: 'think', 623: 'thinly', 624: 'this', 625: 'though', 626: 'three', 627: 'through', 628: 'tightness', 629: 'time', 630: 'tit', 631: 'to', 632: 'toes', 633: 'told', 634: 'tonight', 635: 'too', 636: 'took', 637: 'toward', 638: 'towered', 639: 'track', 640: 'trees', 641: 'trouble', 642: 'truth', 643: 'try', 644: 'turned', 645: 'twilight', 646: 'twilit', 647: 'twisted', 648: 'two', 649: 'under', 650: 'undergrowth', 651: 'understand', 652: 'unease', 653: 'unmanned', 654: 'unwary', 655: 'up', 656: 'urged', 657: 'us', 658: 'veteran', 659: 'vocation', 660: 'voice', 661: 'waiting', 662: 'wanted', 663: 'wardrobe', 664: 'warhorse', 665: 'warm', 666: 'warmly', 667: 'warrior', 668: 'was', 669: 'watch', 670: 'watched', 671: 'watches', 672: 'watching', 673: 'water', 674: 'way', 675: 'we', 676: 'weak', 677: 'weapons', 678: 'weather', 679: 'week', 680: 'weeping', 681: 'well', 682: 'went', 683: 'were', 684: 'wet', 685: 'what', 686: 'when', 687: 'where', 688: 'while', 689: 'whispered', 690: 'wilderness', 691: 'wildling', 692: 'wildlings', 693: 'wind', 694: 'wine', 695: 'winter', 696: 'wished', 697: 'with', 698: 'wolf', 699: 'woman', 700: 'women', 701: 'wood', 702: 'woods', 703: 'wool', 704: 'woolen', 705: 'wore', 706: 'worse', 707: 'worst', 708: 'would', 709: 'wounded', 710: 'wrong', 711: 'year', 712: 'years', 713: 'you', 714: 'young', 715: 'youngest', 716: 'your', 717: 'youth'}\n",
            "\n",
            "Word to Index:\n",
            "{\"'\": 0, \"'ll\": 1, \"'re\": 2, \"'s\": 3, \"'ve\": 4, ';': 5, 'A': 6, 'Aemon': 7, 'All': 8, 'And': 9, 'Are': 10, 'At': 11, 'Best': 12, 'Bet': 13, 'Bright': 14, 'Brother': 15, 'But': 16, 'Ca': 17, 'Dead': 18, 'Despite': 19, 'Did': 20, 'Do': 21, 'Each': 22, 'Eight': 23, 'Especially': 24, 'Ever': 25, 'Everyone': 26, 'Fallen': 27, 'Fear': 28, 'Fire': 29, 'First': 30, 'Frostfallen': 31, 'Game': 32, 'Gared': 33, 'Have': 34, 'He': 35, 'Heavy-looking': 36, 'His': 37, 'I': 38, 'Ice': 39, 'If': 40, 'Is': 41, 'It': 42, 'Leave': 43, 'Liste': 44, 'Maester': 45, 'Mallister': 46, 'Mallisters': 47, 'Men': 48, 'Mormont': 49, 'Most': 50, 'Mounted': 51, 'My': 52, 'Never': 53, 'Night': 54, 'Nine': 55, 'No': 56, 'Not': 57, 'Nothing': 58, 'One': 59, 'Or': 60, 'PROLOGUE': 61, 'Peaceful': 62, 'Perhaps': 63, 'Royce': 64, 'Ser': 65, 'Some': 66, 'Something': 67, 'Somewhere': 68, 'Song': 69, 'Such': 70, 'Sworn': 71, 'Tell': 72, 'The': 73, 'Then': 74, 'There': 75, 'They': 76, 'Thrones': 77, 'Today': 78, 'Twilight': 79, 'Two': 80, 'Under': 81, 'Until': 82, 'Wall': 83, 'Watch': 84, 'Waymar': 85, 'We': 86, 'Weeping': 87, 'Well': 88, 'What': 89, 'When': 90, 'Why': 91, 'Will': 92, 'Yes': 93, 'Yet': 94, 'You': 95, 'a': 96, 'about': 97, 'above': 98, 'accustomed': 99, 'adjusted': 100, 'admitted': 101, 'after': 102, 'afterward': 103, 'again': 104, 'against': 105, 'all': 106, 'an': 107, 'ancient': 108, 'and': 109, 'anger': 110, 'any': 111, 'anything': 112, 'are': 113, 'around': 114, 'as': 115, 'asked': 116, 'at': 117, 'atop': 118, 'away': 119, 'axe': 120, 'back': 121, 'bait': 122, 'band': 123, 'barely': 124, 'barracks': 125, 'be': 126, 'been': 127, 'before': 128, 'began': 129, 'behind': 130, 'being': 131, 'believe': 132, 'beneath': 133, 'beside': 134, 'best': 135, 'better': 136, 'beyond': 137, 'black': 138, 'blood': 139, 'bloody': 140, 'blowing': 141, 'bodies': 142, 'boiled': 143, 'boots': 144, 'both': 145, 'bound': 146, 'bowels': 147, 'bows': 148, 'boy': 149, 'branches': 150, 'brother': 151, 'brothers': 152, 'brought': 153, 'bruise': 154, 'bucks': 155, 'burning': 156, 'burns': 157, 'business': 158, 'but': 159, 'by': 160, 'called': 161, 'came': 162, 'camp': 163, 'can': 164, 'care': 165, 'carefully': 166, 'careless': 167, 'casually': 168, 'caught': 169, 'certainty': 170, 'chatter': 171, 'children': 172, 'chill': 173, 'choice': 174, 'clad': 175, 'clear': 176, 'cloak': 177, 'close': 178, 'closer': 179, 'cloudless': 180, 'coat': 181, 'cocksure': 182, 'cold': 183, 'color': 184, 'come': 185, 'comes': 186, 'commander': 187, 'concerned': 188, 'could': 189, 'couple': 190, 'covered': 191, 'crowning': 192, 'cruel': 193, 'crust': 194, 'cups': 195, 'cut': 196, 'dared': 197, 'dark': 198, 'darkness': 199, 'day': 200, 'days': 201, 'dead': 202, 'deep': 203, 'deepened': 204, 'deepening': 205, 'deign': 206, 'destrier': 207, 'details': 208, 'did': 209, 'different': 210, 'discover': 211, 'disdainful': 212, 'disinterest': 213, 'dismounted': 214, 'distance': 215, 'do': 216, 'does': 217, 'done': 218, 'double-bladed': 219, 'down': 220, 'dozen': 221, 'drag': 222, 'drape': 223, 'draw': 224, 'drawn': 225, 'dream': 226, 'dress': 227, 'driving': 228, 'drowsy': 229, 'ear': 230, 'ears': 231, 'easier': 232, 'echoed': 233, 'edge': 234, 'eight': 235, 'eighteen': 236, 'eloquence': 237, 'else': 238, 'end': 239, 'endless': 240, 'enemy': 241, 'enough': 242, 'even': 243, 'ever': 244, 'every': 245, 'everything': 246, 'eyes': 247, 'face': 248, 'fade': 249, 'faded': 250, 'fallen': 251, 'falling': 252, 'far-eyes': 253, 'farther': 254, 'fear': 255, 'feel': 256, 'feeling': 257, 'feet': 258, 'felt': 259, 'few': 260, 'fierce': 261, 'fifty': 262, 'fight': 263, 'fill': 264, 'find': 265, 'fine': 266, 'finger': 267, 'fire': 268, 'firepit': 269, 'fires': 270, 'first': 271, 'flurry': 272, 'flushed': 273, 'foot': 274, 'for': 275, 'forest': 276, 'fortnight': 277, 'forty': 278, 'found': 279, 'four': 280, 'freeriders': 281, 'freeze': 282, 'frighten': 283, 'from': 284, 'front': 285, 'frosts': 286, 'frowning': 287, 'froze': 288, 'frozen': 289, 'full': 290, 'fur': 291, 'garron': 292, 'garrons': 293, 'gave': 294, 'gets': 295, 'getting': 296, 'given': 297, 'giving': 298, 'glanced': 299, 'glared': 300, 'gleaming': 301, 'glory': 302, 'gloves': 303, 'gnarled': 304, 'go': 305, 'good': 306, 'got': 307, 'graceful': 308, 'grateful': 309, 'great': 310, 'grey-eyed': 311, 'grizzled': 312, 'ground': 313, 'grow': 314, 'grown': 315, 'hackles': 316, 'had': 317, 'half': 318, 'half-alive': 319, 'half-bored': 320, 'half-distracted': 321, 'half-hid': 322, 'half-moon': 323, 'hand': 324, 'handsome': 325, 'hard': 326, 'haunted': 327, 'have': 328, 'he': 329, 'heads': 330, 'hear': 331, 'heirs': 332, 'hellbent': 333, 'here': 334, 'hidden': 335, 'him': 336, 'himself': 337, 'hint': 338, 'his': 339, 'holes': 340, 'honor': 341, 'hood': 342, 'hope': 343, 'horse': 344, 'hot': 345, 'house': 346, 'how': 347, 'howled': 348, 'howling': 349, 'huge': 350, 'hunched': 351, 'hundred': 352, 'hunter': 353, 'ice': 354, 'if': 355, 'impatiently': 356, 'implacable': 357, 'in': 358, 'inside': 359, 'insisted': 360, 'insofar': 361, 'insolent': 362, 'interrupt': 363, 'into': 364, 'iron': 365, 'ironwood': 366, 'is': 367, 'it': 368, 'its': 369, 'joined': 370, 'just': 371, 'kill': 372, 'killed': 373, 'knife': 374, 'knight': 375, 'known': 376, 'lad': 377, 'last': 378, 'later': 379, 'laugh': 380, 'laughed': 381, 'lay': 382, 'layers': 383, 'lead': 384, 'lean-to': 385, 'learned': 386, 'least': 387, 'leather': 388, 'leaves': 389, 'left': 390, 'less': 391, 'let': 392, 'light': 393, 'like': 394, 'little': 395, 'living': 396, 'long': 397, 'look': 398, 'looked': 399, 'lord': 400, 'lordling': 401, 'lordlings': 402, 'losing': 403, 'loud': 404, 'loved': 405, 'lying': 406, \"m'lord\": 407, 'made': 408, 'make': 409, 'making': 410, 'man': 411, 'man-at-arms': 412, 'many': 413, 'maybe': 414, 'me': 415, 'means': 416, 'men': 417, 'might': 418, 'mighty': 419, 'miles': 420, 'milk': 421, 'moleskin': 422, 'moment': 423, 'moon': 424, 'more': 425, 'mother': 426, 'mount': 427, 'mouth': 428, 'move': 429, 'moved': 430, 'moving': 431, 'much': 432, 'mulled': 433, 'must': 434, 'muttered': 435, 'my': 436, 'myself': 437, \"n't\": 438, 'near': 439, 'neither': 440, 'nervous': 441, 'never': 442, 'next': 443, 'nice': 444, 'night': 445, 'nine': 446, 'no': 447, 'nodded': 448, 'north': 449, 'northwest': 450, 'not': 451, 'note': 452, 'nothing': 453, 'now': 454, 'nurse': 455, 'obey': 456, 'observed': 457, 'of': 458, 'off': 459, 'old': 460, 'older': 461, 'on': 462, 'one': 463, 'only': 464, 'or': 465, 'order': 466, 'orders': 467, 'ought': 468, 'our': 469, 'out': 470, 'over': 471, 'own': 472, 'pace': 473, 'pain': 474, 'pants': 475, 'past': 476, 'paused': 477, 'perilous': 478, 'picking': 479, 'piece': 480, 'plain': 481, 'poacher': 482, 'pointed': 483, 'position': 484, 'prepared': 485, 'pretty': 486, 'pride': 487, 'proof': 488, 'pulled': 489, 'purple': 490, 'put': 491, 'putting': 492, 'quarrel': 493, 'quick': 494, 'quieter': 495, 'raiders': 496, 'ranging': 497, 'rangings': 498, 'rather': 499, 'real': 500, 'rear': 501, 'red': 502, 'red-handed': 503, 'reflected': 504, 'reflective': 505, 'remind': 506, 'replied': 507, 'reply': 508, 'rest': 509, 'restlessly': 510, 'ridden': 511, 'ride': 512, 'ridge': 513, 'riding': 514, 'right': 515, 'ringmail': 516, 'rise': 517, 'risen': 518, 'rock': 519, 'rode': 520, 'roots': 521, 'rose': 522, 'rushing': 523, 'rustle': 524, 'sable': 525, 'safety': 526, 'said': 527, 'same': 528, 'sat': 529, 'saw': 530, 'say': 531, 'says': 532, 'scars': 533, 'sea': 534, 'see': 535, 'seemed': 536, 'seen': 537, 'sense': 538, 'sent': 539, 'sha': 540, 'shaggy': 541, 'share': 542, 'shared': 543, 'she': 544, 'shelter': 545, 'shiver': 546, 'shivered': 547, 'shivering': 548, 'should': 549, 'shrugged': 550, 'silent': 551, 'sin': 552, 'sing': 553, 'sinking': 554, 'sinks': 555, 'sit': 556, 'sitting': 557, 'skinning': 558, 'sky': 559, 'sleep': 560, 'sleeping': 561, 'slender': 562, 'smaller': 563, 'smile': 564, 'smiled': 565, 'snorting': 566, 'snow': 567, 'snows': 568, 'so': 569, 'soft': 570, 'softly': 571, 'something': 572, 'son': 573, 'songs': 574, 'sooner': 575, 'southron': 576, 'spent': 577, 'stamp': 578, 'staring': 579, 'stars': 580, 'start': 581, 'starts': 582, 'steals': 583, 'still': 584, 'stirred': 585, 'stones': 586, 'stopping': 587, 'stories': 588, 'storm': 589, 'stream': 590, 'strength': 591, 'studied': 592, 'stumps': 593, 'suggested': 594, 'sullen': 595, 'supple': 596, 'suppressed': 597, 'surely': 598, 'suspected': 599, 'swords': 600, 'take': 601, 'taken': 602, 'talent': 603, 'talks': 604, 'taste': 605, 'teeth': 606, 'tell': 607, 'tension': 608, 'terrors': 609, 'than': 610, 'that': 611, 'the': 612, 'their': 613, 'them': 614, 'then': 615, 'there': 616, 'these': 617, 'they': 618, 'thick': 619, 'thing': 620, 'things': 621, 'think': 622, 'thinly': 623, 'this': 624, 'though': 625, 'three': 626, 'through': 627, 'tightness': 628, 'time': 629, 'tit': 630, 'to': 631, 'toes': 632, 'told': 633, 'tonight': 634, 'too': 635, 'took': 636, 'toward': 637, 'towered': 638, 'track': 639, 'trees': 640, 'trouble': 641, 'truth': 642, 'try': 643, 'turned': 644, 'twilight': 645, 'twilit': 646, 'twisted': 647, 'two': 648, 'under': 649, 'undergrowth': 650, 'understand': 651, 'unease': 652, 'unmanned': 653, 'unwary': 654, 'up': 655, 'urged': 656, 'us': 657, 'veteran': 658, 'vocation': 659, 'voice': 660, 'waiting': 661, 'wanted': 662, 'wardrobe': 663, 'warhorse': 664, 'warm': 665, 'warmly': 666, 'warrior': 667, 'was': 668, 'watch': 669, 'watched': 670, 'watches': 671, 'watching': 672, 'water': 673, 'way': 674, 'we': 675, 'weak': 676, 'weapons': 677, 'weather': 678, 'week': 679, 'weeping': 680, 'well': 681, 'went': 682, 'were': 683, 'wet': 684, 'what': 685, 'when': 686, 'where': 687, 'while': 688, 'whispered': 689, 'wilderness': 690, 'wildling': 691, 'wildlings': 692, 'wind': 693, 'wine': 694, 'winter': 695, 'wished': 696, 'with': 697, 'wolf': 698, 'woman': 699, 'women': 700, 'wood': 701, 'woods': 702, 'wool': 703, 'woolen': 704, 'wore': 705, 'worse': 706, 'worst': 707, 'would': 708, 'wounded': 709, 'wrong': 710, 'year': 711, 'years': 712, 'you': 713, 'young': 714, 'youngest': 715, 'your': 716, 'youth': 717}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wordToVec(sentence):\n",
        "  em = []\n",
        "  sentence = tokenize(sentence)\n",
        "  for word in sentence:\n",
        "    em.append(word_to_index[word])\n",
        "  return em"
      ],
      "metadata": {
        "id": "o8FqLbYRL1ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oneHot(arr):\n",
        "  temp = [0]*len(all_words)\n",
        "  temp[arr[0]] = 1\n",
        "  return temp"
      ],
      "metadata": {
        "id": "wKBALcunvSFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = []\n",
        "# y_train = []\n",
        "\n",
        "# def makeTrain(text, batch_size=9):\n",
        "#     words = tokenize(text)\n",
        "#     words = [word for word in words if word not in ignore_words]\n",
        "#     for i in range(0, len(words), batch_size):\n",
        "#         batch = words[i:i + batch_size]\n",
        "#         vecBatch_X = []\n",
        "#         vecBatch_y = []\n",
        "#         for index, w in enumerate(batch):\n",
        "#           if index!=8:\n",
        "#             vecBatch_X.append(word_to_index[w])\n",
        "#           else:\n",
        "#             vecBatch_y.append(word_to_index[w])\n",
        "\n",
        "#         oneHotVec = oneHot(vecBatch_y)\n",
        "#         X_train.append(vecBatch_X)\n",
        "#         y_train.append(oneHotVec)\n",
        "\n",
        "# makeTrain(content)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "def makeTrainSliding(text, window_size=10, stride=1):\n",
        "    words = tokenize(text)\n",
        "    words = [word for word in words if word not in ignore_words]\n",
        "    for i in range(0, len(words) - window_size + 1, stride):\n",
        "        window = words[i:i + window_size]\n",
        "\n",
        "        vecBatch_X = [word_to_index[w] for w in window[:-1]]  # Input words\n",
        "        vecBatch_y = [word_to_index[window[-1]]]  # Target word\n",
        "\n",
        "        oneHotVec = oneHot(vecBatch_y)\n",
        "        X_train.append(vecBatch_X)\n",
        "        y_train.append(oneHotVec)\n",
        "\n",
        "makeTrainSliding(content, window_size=9, stride=1)\n"
      ],
      "metadata": {
        "id": "fuuRmxoqOsZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[-1])\n",
        "print(len(y_train[-1]))\n",
        "\n",
        "X_train = X_train[:1000]\n",
        "y_train = y_train[:1000]\n",
        "\n"
      ],
      "metadata": {
        "id": "xm6KE_FjWPhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b0e44c-125a-4497-c0dd-31a7f77baf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[616, 17, 438, 713, 256, 368, 33, 116]\n",
            "718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "-oO7V9hJVWXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, vocab_size, input_size, hidden_size, num_layers=1):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, input_size, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embed = self.embedding(x)\n",
        "    lstm_out, _ = self.lstm(embed)\n",
        "    output = self.linear(lstm_out)\n",
        "    return output"
      ],
      "metadata": {
        "id": "G4uIUmkMVTuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "num_epochs = 1\n",
        "batch_size = 8\n",
        "learning_rate = 0.001\n",
        "input_size = len(X_train[0])\n",
        "vocab_size = len(all_words)\n",
        "hidden_size = 128\n",
        "output_size = 1\n",
        "print(input_size, output_size)\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.num_samples = len(X_train)\n",
        "        self.x_data = torch.tensor(X_train, dtype=torch.long).to(device)\n",
        "        self.y_data = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.tensor(self.x_data[index], dtype=torch.long), torch.tensor(self.y_data[index], dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
      ],
      "metadata": {
        "id": "mYQZBVGsTKQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acf8ecf-fa0a-4887-8557-7376427af563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(vocab_size, input_size, hidden_size).to(device)"
      ],
      "metadata": {
        "id": "_KU7EPIQ20Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "LDVbWlaBymS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "      words = words.to(device)\n",
        "      labels = labels.to(device)  # No need to cast to dtype=torch.long\n",
        "\n",
        "      outputs = model(words)\n",
        "\n",
        "      # Ensure outputs and labels are of compatible shapes\n",
        "      # outputs = outputs.view(-1, output_size)\n",
        "      # labels = labels.view(-1)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(f'final loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "8jR42sPVybd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00ac5da-0df1-4254-f132-09296c383155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0a43a0d8c392>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(self.x_data[index], dtype=torch.long), torch.tensor(self.y_data[index], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final loss: 0.0435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "McFzgIB7yg9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb-G0aPS5y_P",
        "outputId": "b232946c-7640-4aef-9921-130d644f4c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (embedding): Embedding(718, 8, padding_idx=0)\n",
              "  (lstm): LSTM(8, 128, batch_first=True)\n",
              "  (linear): Linear(in_features=128, out_features=718, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define your NeuralNetwork class here\n",
        "\n",
        "# Assuming you've defined the necessary classes and variables\n",
        "\n",
        "# Load your trained model\n",
        "model = NeuralNetwork(vocab_size, input_size, hidden_size, num_layers=1)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "# Define a function to predict the next word\n",
        "def predict_next_word(model, input_text, word_to_index, index_to_word):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # Convert input_text to a tensor\n",
        "        input_sequence = [word_to_index[word] for word in input_text.split()]\n",
        "        input_tensor = torch.tensor(input_sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "        # Get the model's prediction\n",
        "        output = model(input_tensor)\n",
        "        # Find the index of the predicted word\n",
        "        predicted_index = torch.argmax(output, dim=2)[:, -1].item()\n",
        "        print(predicted_index)\n",
        "\n",
        "        # Convert the predicted index to the predicted word\n",
        "        predicted_word = index_to_word[predicted_index]\n",
        "\n",
        "    return predicted_word"
      ],
      "metadata": {
        "id": "cf7QKeG65xMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"We should start back Gared urged\"\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "  next_word = predict_next_word(model, input_text, word_to_index, index_to_word)\n",
        "  input_text = input_text+\" \"+next_word\n",
        "\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EEr0p4Z-LXw",
        "outputId": "3e95fb76-d311-41ad-987a-550386fd2b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "182\n",
            "We should start back Gared urged cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure cocksure\n"
          ]
        }
      ]
    }
  ]
}